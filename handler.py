
import runpod
from runpod.serverless.utils import rp_upload
import os
import websocket
import base64
import json
import uuid
import logging
import urllib.request
import urllib.parse
import binascii  # Base64 ì—ëŸ¬ ì²˜ë¦¬ë¥¼ ìœ„í•´ import
import subprocess
import time
from functools import lru_cache


# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# CUDA ê²€ì‚¬ ë° ì„¤ì •


def check_cuda_availability():
    """CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ê³  í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."""
    try:
        import torch
        if torch.cuda.is_available():
            logger.info("âœ… CUDA is available and working")
            os.environ['CUDA_VISIBLE_DEVICES'] = '0'
            return True
        else:
            logger.error("âŒ CUDA is not available")
            raise RuntimeError("CUDA is required but not available")
    except Exception as e:
        logger.error(f"âŒ CUDA check failed: {e}")
        raise RuntimeError(f"CUDA initialization failed: {e}")


# CUDA ê²€ì‚¬ ì‹¤í–‰
try:
    cuda_available = check_cuda_availability()
    if not cuda_available:
        raise RuntimeError("CUDA is not available")
except Exception as e:
    logger.error(f"Fatal error: {e}")
    logger.error("Exiting due to CUDA requirements not met")
    exit(1)


server_address = os.getenv('SERVER_ADDRESS', '127.0.0.1')

# Cache workflow JSON Ä‘á»ƒ trÃ¡nh Ä‘á»c file má»—i láº§n


@lru_cache(maxsize=2)
def load_workflow_cached(workflow_path):
    """Load workflow vá»›i caching"""
    with open(workflow_path, 'r') as file:
        return json.load(file)


def queue_prompt(prompt, client_id):
    """Queue prompt vá»›i client_id"""
    url = f"http://{server_address}:8188/prompt"
    logger.info(f"Queueing prompt to: {url}")
    p = {"prompt": prompt, "client_id": client_id}
    data = json.dumps(p).encode('utf-8')
    req = urllib.request.Request(url, data=data)
    return json.loads(urllib.request.urlopen(req).read())


def get_image(filename, subfolder, folder_type):
    url = f"http://{server_address}:8188/view"
    logger.info(f"Getting image from: {url}")
    data = {"filename": filename, "subfolder": subfolder, "type": folder_type}
    url_values = urllib.parse.urlencode(data)
    with urllib.request.urlopen(f"{url}?{url_values}") as response:
        return response.read()


def get_history(prompt_id):
    url = f"http://{server_address}:8188/history/{prompt_id}"
    logger.info(f"Getting history from: {url}")
    with urllib.request.urlopen(url) as response:
        return json.loads(response.read())


def get_images(ws, prompt, client_id):
    """Get images tá»« ComfyUI workflow vá»›i timeout handling"""
    prompt_id = queue_prompt(prompt, client_id)['prompt_id']
    output_images = {}

    # Wait for execution to complete vá»›i timeout
    max_wait_time = 240  # 4 phÃºt max cho execution
    start_time = time.time()

    while True:
        # Check timeout
        if time.time() - start_time > max_wait_time:
            raise Exception(f"Workflow execution timeout sau {max_wait_time}s")

        try:
            out = ws.recv()
            if isinstance(out, str):
                message = json.loads(out)
                if message['type'] == 'executing':
                    data = message['data']
                    if data['node'] is None and data['prompt_id'] == prompt_id:
                        break
        except websocket.WebSocketTimeoutException:
            raise Exception("WebSocket timeout trong khi chá» execution")
        except Exception as e:
            logger.warning(f"Error receiving WebSocket message: {e}")
            continue

    history = get_history(prompt_id)[prompt_id]
    for node_id in history['outputs']:
        node_output = history['outputs'][node_id]
        images_output = []
        if 'images' in node_output:
            for image in node_output['images']:
                image_data = get_image(
                    image['filename'], image['subfolder'], image['type'])
                # bytes ê°ì²´ë¥¼ base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ê²Œ ë³€í™˜
                if isinstance(image_data, bytes):
                    image_data = base64.b64encode(image_data).decode('utf-8')
                images_output.append(image_data)
        output_images[node_id] = images_output

    return output_images


def load_workflow(workflow_path):
    """Load workflow sá»­ dá»¥ng cache"""
    return load_workflow_cached(workflow_path)

# ------------------------------
# ì…ë ¥ ì²˜ë¦¬ ìœ í‹¸ (path/url/base64)
# ------------------------------


def process_input(input_data, temp_dir, output_filename, input_type):
    """ì…ë ¥ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ì—¬ íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
    - input_type: "path" | "url" | "base64"
    """
    if input_type == "path":
        logger.info(f"ğŸ“ ê²½ë¡œ ì…ë ¥ ì²˜ë¦¬: {input_data}")
        return input_data
    elif input_type == "url":
        logger.info(f"ğŸŒ URL ì…ë ¥ ì²˜ë¦¬: {input_data}")
        os.makedirs(temp_dir, exist_ok=True)
        file_path = os.path.abspath(os.path.join(temp_dir, output_filename))
        return download_file_from_url(input_data, file_path)
    elif input_type == "base64":
        logger.info("ğŸ”¢ Base64 ì…ë ¥ ì²˜ë¦¬")
        return save_base64_to_file(input_data, temp_dir, output_filename)
    else:
        raise Exception(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì…ë ¥ íƒ€ì…: {input_type}")


def download_file_from_url(url, output_path):
    """URLì—ì„œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    try:
        result = subprocess.run([
            'wget', '-O', output_path, '--no-verbose', url
        ], capture_output=True, text=True)
        if result.returncode == 0:
            logger.info(f"âœ… URLì—ì„œ íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí–ˆìŠµë‹ˆë‹¤: {url} -> {output_path}")
            return output_path
        else:
            logger.error(f"âŒ wget ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {result.stderr}")
            raise Exception(f"URL ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {result.stderr}")
    except subprocess.TimeoutExpired:
        logger.error("âŒ ë‹¤ìš´ë¡œë“œ ì‹œê°„ ì´ˆê³¼")
        raise Exception("ë‹¤ìš´ë¡œë“œ ì‹œê°„ ì´ˆê³¼")
    except Exception as e:
        logger.error(f"âŒ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise Exception(f"ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


def save_base64_to_file(base64_data, temp_dir, output_filename):
    """Base64 ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜"""
    try:
        decoded_data = base64.b64decode(base64_data)
        os.makedirs(temp_dir, exist_ok=True)
        file_path = os.path.abspath(os.path.join(temp_dir, output_filename))
        with open(file_path, 'wb') as f:
            f.write(decoded_data)
        logger.info(f"âœ… Base64 ì…ë ¥ì„ '{file_path}' íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
        return file_path
    except (binascii.Error, ValueError) as e:
        logger.error(f"âŒ Base64 ë””ì½”ë”© ì‹¤íŒ¨: {e}")
        raise Exception(f"Base64 ë””ì½”ë”© ì‹¤íŒ¨: {e}")


def handler(job):
    """
    Handler function vá»›i timeout vÃ  queue time checking
    """
    job_input = job.get("input", {})
    job_id = job.get("id", "unknown")

    # Kiá»ƒm tra náº¿u job Ä‘Ã£ bá»‹ cancel (RunPod sáº½ tá»± Ä‘á»™ng cancel jobs trong queue quÃ¡ lÃ¢u)
    # RunPod sáº½ khÃ´ng gá»i handler náº¿u job Ä‘Ã£ bá»‹ cancel, nhÆ°ng ta váº«n check Ä‘á»ƒ cháº¯c cháº¯n
    logger.info(f"Processing job {job_id}")
    logger.info(f"Received job input: {job_input}")

    # Validate input sá»›m Ä‘á»ƒ fail fast
    required_fields = ["prompt", "seed", "width", "height"]
    missing_fields = [
        field for field in required_fields if field not in job_input]
    if missing_fields:
        raise ValueError(f"Missing required fields: {missing_fields}")

    # Timeout cho toÃ n bá»™ job (5 phÃºt = 300 giÃ¢y)
    # Náº¿u job cháº¡y quÃ¡ lÃ¢u, sáº½ raise exception vÃ  RunPod sáº½ mark job lÃ  failed
    job_start_time = time.time()
    JOB_TIMEOUT_SECONDS = 300  # 5 phÃºt

    # Táº¡o client_id má»›i cho má»—i job Ä‘á»ƒ trÃ¡nh WebSocket conflicts
    client_id = str(uuid.uuid4())
    task_id = f"task_{uuid.uuid4()}"

    # ------------------------------
    # ì´ë¯¸ì§€ ì…ë ¥ ìˆ˜ì§‘ (1ê°œ ë˜ëŠ” 2ê°œ)
    # ì§€ì› í‚¤: image_path | image_url | image_base64
    #         image_path_2 | image_url_2 | image_base64_2
    # ------------------------------
    image1_path = None
    image2_path = None

    if "image_path" in job_input:
        image1_path = process_input(
            job_input["image_path"], task_id, "input_image_1.jpg", "path")
    elif "image_url" in job_input:
        image1_path = process_input(
            job_input["image_url"], task_id, "input_image_1.jpg", "url")
    elif "image_base64" in job_input:
        image1_path = process_input(
            job_input["image_base64"], task_id, "input_image_1.jpg", "base64")

    if "image_path_2" in job_input:
        image2_path = process_input(
            job_input["image_path_2"], task_id, "input_image_2.jpg", "path")
    elif "image_url_2" in job_input:
        image2_path = process_input(
            job_input["image_url_2"], task_id, "input_image_2.jpg", "url")
    elif "image_base64_2" in job_input:
        image2_path = process_input(
            job_input["image_base64_2"], task_id, "input_image_2.jpg", "base64")

    if image2_path:
        workflow_path = "/qwen_image_edit_2.json"
    else:
        workflow_path = "/qwen_image_edit_1.json"

    prompt = load_workflow(workflow_path)

    prompt["78"]["inputs"]["image"] = image1_path
    if image2_path:
        prompt["123"]["inputs"]["image"] = image2_path

    prompt["111"]["inputs"]["prompt"] = job_input["prompt"]

    prompt["3"]["inputs"]["seed"] = job_input["seed"]
    prompt["128"]["inputs"]["value"] = job_input["width"]
    prompt["129"]["inputs"]["value"] = job_input["height"]

    # Kiá»ƒm tra timeout trÆ°á»›c khi tiáº¿p tá»¥c
    elapsed_time = time.time() - job_start_time
    if elapsed_time > JOB_TIMEOUT_SECONDS:
        raise Exception(
            f"Job timeout sau {elapsed_time:.1f}s (giá»›i háº¡n: {JOB_TIMEOUT_SECONDS}s)")

    ws_url = f"ws://{server_address}:8188/ws?clientId={client_id}"
    logger.info(f"Connecting to WebSocket: {ws_url}")

    # ë¨¼ì € HTTP ì—°ê²°ì´ ê°€ëŠ¥í•œì§€ í™•ì¸
    http_url = f"http://{server_address}:8188/"
    logger.info(f"Checking HTTP connection to: {http_url}")

    # HTTP ì—°ê²° í™•ì¸ (ìµœëŒ€ 1ë¶„, nhÆ°ng check timeout má»—i láº§n)
    max_http_attempts = 60  # Giáº£m tá»« 180 xuá»‘ng 60 Ä‘á»ƒ nhanh hÆ¡n
    for http_attempt in range(max_http_attempts):
        # Kiá»ƒm tra timeout
        elapsed_time = time.time() - job_start_time
        if elapsed_time > JOB_TIMEOUT_SECONDS:
            raise Exception(
                f"Job timeout trong khi chá» HTTP connection ({elapsed_time:.1f}s)")

        try:
            response = urllib.request.urlopen(http_url, timeout=5)
            logger.info(f"HTTP ì—°ê²° ì„±ê³µ (ì‹œë„ {http_attempt+1})")
            break
        except Exception as e:
            logger.warning(
                f"HTTP ì—°ê²° ì‹¤íŒ¨ (ì‹œë„ {http_attempt+1}/{max_http_attempts}): {e}")
            if http_attempt == max_http_attempts - 1:
                raise Exception("ComfyUI ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
            time.sleep(1)

    # Kiá»ƒm tra timeout trÆ°á»›c khi connect WebSocket
    elapsed_time = time.time() - job_start_time
    if elapsed_time > JOB_TIMEOUT_SECONDS:
        raise Exception(
            f"Job timeout trÆ°á»›c khi connect WebSocket ({elapsed_time:.1f}s)")

    ws = websocket.WebSocket()
    # ì›¹ì†Œì¼“ ì—°ê²° ì‹œë„ (ìµœëŒ€ 2ë¶„, giáº£m tá»« 3 phÃºt)
    max_attempts = int(120/5)  # 2 phÃºt (má»—i 5 giÃ¢y thá»­ 1 láº§n)
    for attempt in range(max_attempts):
        # Kiá»ƒm tra timeout má»—i láº§n thá»­
        elapsed_time = time.time() - job_start_time
        if elapsed_time > JOB_TIMEOUT_SECONDS:
            raise Exception(
                f"Job timeout trong khi chá» WebSocket connection ({elapsed_time:.1f}s)")

        try:
            ws.connect(ws_url)
            logger.info(f"ì›¹ì†Œì¼“ ì—°ê²° ì„±ê³µ (ì‹œë„ {attempt+1})")
            break
        except Exception as e:
            logger.warning(f"ì›¹ì†Œì¼“ ì—°ê²° ì‹¤íŒ¨ (ì‹œë„ {attempt+1}/{max_attempts}): {e}")
            if attempt == max_attempts - 1:
                raise Exception("ì›¹ì†Œì¼“ ì—°ê²° ì‹œê°„ ì´ˆê³¼ (2 phÃºt)")
            time.sleep(5)

    # Kiá»ƒm tra timeout trÆ°á»›c khi xá»­ lÃ½ images
    elapsed_time = time.time() - job_start_time
    if elapsed_time > JOB_TIMEOUT_SECONDS:
        ws.close()
        raise Exception(
            f"Job timeout trÆ°á»›c khi xá»­ lÃ½ images ({elapsed_time:.1f}s)")

    try:
        images = get_images(ws, prompt, client_id)
    finally:
        ws.close()

    # Log thá»i gian hoÃ n thÃ nh
    total_time = time.time() - job_start_time
    logger.info(f"Job {job_id} hoÃ n thÃ nh trong {total_time:.1f}s")

    # Cleanup temp files (náº¿u cÃ³)
    try:
        import shutil
        temp_dir = f"/tmp/{task_id}" if os.path.exists(
            f"/tmp/{task_id}") else None
        if temp_dir and os.path.exists(temp_dir):
            shutil.rmtree(temp_dir, ignore_errors=True)
            logger.debug(f"Cleaned up temp directory: {temp_dir}")
    except Exception as e:
        logger.warning(f"Failed to cleanup temp files: {e}")

    # ì´ë¯¸ì§€ê°€ ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
    if not images:
        return {"error": "ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

    # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ ë°˜í™˜
    for node_id in images:
        if images[node_id]:
            return {"image": images[node_id][0]}

    return {"error": "ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}


# Cáº¥u hÃ¬nh RunPod serverless vá»›i timeout
# Job timeout: 5 phÃºt (300 giÃ¢y) - jobs cháº¡y quÃ¡ lÃ¢u sáº½ bá»‹ cancel
# Queue timeout Ä‘Æ°á»£c cáº¥u hÃ¬nh trong RunPod Console (xem OPTIMIZATION_GUIDE.md)
runpod.serverless.start({
    "handler": handler,
    # CÃ³ thá»ƒ thÃªm cÃ¡c config khÃ¡c á»Ÿ Ä‘Ã¢y náº¿u RunPod SDK há»— trá»£
})
